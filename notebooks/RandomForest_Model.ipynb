{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump\n",
    "from time import time\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/fazleem/bank-marketing/3f0e6abfe9dc497eab40deb2f7fd2700\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<comet_ml.Experiment object at 0x7f7ee0e8ff10>\n"
     ]
    }
   ],
   "source": [
    "with open('../data/raw/comet_creds.json') as file:\n",
    "    comet_creds = json.load(file)\n",
    "exp = Experiment(api_key=comet_creds['api_key'], project_name=comet_creds['project_name'],workspace=comet_creds[\"workspace\"])    \n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../data/interim/train_data.npy\", allow_pickle=True)\n",
    "dev_data = np.load(\"../data/interim/dev_data.npy\", allow_pickle=True)\n",
    "save_model = \"../models/model_randomforest.pkl\"\n",
    "n_experiments = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
    "       'target', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
    "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
    "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
    "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
    "       'education_primary', 'education_secondary', 'education_tertiary',\n",
    "       'education_unknown', 'credit_default_no', 'credit_default_yes',\n",
    "       'housing_no', 'housing_yes', 'personal_loan_no', 'personal_loan_yes',\n",
    "       'contact_type_cellular', 'contact_type_telephone',\n",
    "       'contact_type_unknown', 'month_apr', 'month_aug', 'month_dec',\n",
    "       'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar',\n",
    "       'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "       'previous_campaign_failure', 'previous_campaign_other',\n",
    "       'previous_campaign_success', 'previous_campaign_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36169, 51) (36169,)\n"
     ]
    }
   ],
   "source": [
    "combined_data = np.concatenate([train_data,dev_data])\n",
    "df = pd.DataFrame(combined_data, columns=columns)\n",
    "y = df['target']\n",
    "X = df.drop(['target'], axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 76.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 159.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train acc: 0.9821051222746898\n",
      "XG Boost Train acc: 0.9234283246570725\n"
     ]
    }
   ],
   "source": [
    "# create a pipeline\n",
    "pipeline_rf = Pipeline([('clfrf', RandomForestClassifier()),])\n",
    "pipeline_gboost = Pipeline([('clfgb', GradientBoostingClassifier()),])\n",
    "rf_parameters = {\n",
    "    'clfrf__n_estimators': (100,1000,5000),\n",
    "    'clfrf__max_depth': (None, 5,10, 15),\n",
    "    'clfrf__min_samples_split': (2,4,6)\n",
    "}\n",
    "gb_parameters = {\n",
    "    'clfgb__n_estimators': (100,1000,5000),\n",
    "    'clfgb__max_depth': (None, 5,10, 15),\n",
    "    'clfgb__min_samples_split': (2,4,6)\n",
    "        }\n",
    "sorted(pipeline_rf.get_params().keys())\n",
    "\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(pipeline_rf, rf_parameters, n_iter=10, n_jobs=-1, verbose=1, cv=5, scoring=\"f1_weighted\", random_state=42)\n",
    "random_search_gb = RandomizedSearchCV(pipeline_gboost, gb_parameters, n_iter=10, scoring='f1_weighted', n_jobs=-1, cv=5, verbose=1, random_state=1001)\n",
    "# list of searches that i want to run\n",
    "pipelines = [random_search_rf,random_search_gb]\n",
    "\n",
    "#create dict\n",
    "randomcv_dict = {0:'Random Forest', 1:'Gradient Boost'}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_model = 0\n",
    "best_search = ''\n",
    "\n",
    "#fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X,y)\n",
    "\n",
    "for index,model in enumerate(pipelines):\n",
    "    print(\"{} Train acc: {}\" .format(randomcv_dict[index], model.score(X,y)))\n",
    "    \n",
    "# print(\"Performing random search\")\n",
    "# print(\"Pipeline: \", [name for name, _ in pipeline.steps])\n",
    "# print(\"parameters: \")\n",
    "# pprint(parameters)\n",
    "# t0 = time()\n",
    "# random_search.fit(X, y)\n",
    "# print(\"tuned in %0.4fs\" % (time()-t0))\n",
    "# print('Best_score for Random Forest Classifier',random_search.best_score_)\n",
    "# # print('Best_Parameters for Random Forest classifier',random_search.best_params_)\n",
    "\n",
    "# best_parameters = random_search.best_estimator_.get_params()\n",
    "# for parameter_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" %(parameter_name, best_parameters[parameter_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pipe.cv_results_['params'])):\n",
    "#     exp = Experiment(api_key=comet_creds['api_key'], project_name=comet_creds['project_name'],workspace=comet_creds[\"workspace\"])\n",
    "    for index,values in pipe.cv_results_.items():\n",
    "        if index == \"params\":\n",
    "            exp.log_parameters(values[i])\n",
    "        else:\n",
    "            exp.log_metric(index,values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RF_Tuned_Param(X,Y):\n",
    "#     # Using RandomSearchCV to find out the best set of parameters for RFR and use it for the regression model analysis and prediction:\n",
    "\n",
    "#     # Number of trees in random forest:\n",
    "#     n_estimators = [int(x) for x in np.linspace(start=5, stop= 50, num= 10)]\n",
    "\n",
    "#     # Number of features to consider at every split:\n",
    "#     max_features = ['auto','sqrt','log2']\n",
    "\n",
    "#     # Maximun number of levels in tree:\n",
    "#     max_depth = [int(x) for x in np.linspace(start=10, stop= 30, num= 5)]\n",
    "\n",
    "#     # Minimum number of samples required to split a node:\n",
    "#     min_samples_split = [5,10]\n",
    "\n",
    "#     # Minimum number of samples required at each leaf node\n",
    "#     min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "#     # Bootstrap method:\n",
    "#     bootstrap = [True,False]\n",
    "\n",
    "#     # Create the parameter grid\n",
    "#     param_grid_RF = {'n_estimators': n_estimators,\n",
    "#                   'max_features': max_features,\n",
    "#                   'max_depth': max_depth,\n",
    "#                   'min_samples_split': min_samples_split,\n",
    "#                   'min_samples_leaf': min_samples_leaf,\n",
    "#                   'bootstrap': bootstrap}\n",
    "#     pprint(param_grid_RF)\n",
    "\n",
    "#     # forest = RandomForestRegressor()\n",
    "#     random_search_forest = RandomizedSearchCV(RFR_Model, param_grid_RF, cv=3, n_jobs=6, verbose=1)\n",
    "#     random_search_forest.fit(X, Y)\n",
    "\n",
    "#     # The best parameters for the Random forest regressor obtained from GridSearch CV:\n",
    "#     print('Best_Parameters for Random Forest class',random_search_forest.best_params_)\n",
    "\n",
    "#     # The best score for Random forest regressor after GridSearch CV:\n",
    "#     print('Best_score for Random Forest Regressor',random_search_forest.best_score_)\n",
    "\n",
    "#     return random_search_forest, random_search_forest.best_params_, random_search_forest.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_randomforest.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # RF_Tuned_Param(X,y)\n",
    "dump(pipe.best_estimator_, save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank_marketting",
   "language": "python",
   "name": "bank_marketting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

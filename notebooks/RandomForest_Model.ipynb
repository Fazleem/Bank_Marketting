{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/fazleem/bank-marketing/23b1b6c4d8094406b2a37b0ec3295558\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<comet_ml.Experiment object at 0x7f23d136bee0>\n"
     ]
    }
   ],
   "source": [
    "with open('../data/raw/comet_creds.json') as file:\n",
    "    comet_creds = json.load(file)\n",
    "exp = Experiment(api_key=comet_creds['api_key'], project_name=comet_creds['project_name'],workspace=comet_creds[\"workspace\"])    \n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../data/interim/train_data.npy\", allow_pickle=True)\n",
    "dev_data = np.load(\"../data/interim/dev_data.npy\", allow_pickle=True)\n",
    "save_model = \"../models/model_randomforest.pkl\"\n",
    "n_experiments = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
    "       'target', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
    "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
    "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
    "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
    "       'education_primary', 'education_secondary', 'education_tertiary',\n",
    "       'education_unknown', 'credit_default_no', 'credit_default_yes',\n",
    "       'housing_no', 'housing_yes', 'personal_loan_no', 'personal_loan_yes',\n",
    "       'contact_type_cellular', 'contact_type_telephone',\n",
    "       'contact_type_unknown', 'month_apr', 'month_aug', 'month_dec',\n",
    "       'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar',\n",
    "       'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "       'previous_campaign_failure', 'previous_campaign_other',\n",
    "       'previous_campaign_success', 'previous_campaign_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 52)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36169, 51) (36169,)\n"
     ]
    }
   ],
   "source": [
    "combined_data = np.concatenate([train_data,dev_data])\n",
    "df = pd.DataFrame(combined_data, columns=columns)\n",
    "y = df['target']\n",
    "X = df.drop(['target'], axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing random search\n",
      "Pipeline:  ['clf']\n",
      "parameters: \n",
      "{'clf__max_depth': (None, 5, 10, 15),\n",
      " 'clf__min_samples_split': (2, 4, 6),\n",
      " 'clf__n_estimators': (100, 1000, 5000)}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazleem/Desktop/DataScience/bank_marketting/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 38.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned in 2335.1107s\n",
      "Best_score for Random Forest Classifier 0.8949795896795077\n",
      "\tclf__max_depth: None\n",
      "\tclf__min_samples_split: 4\n",
      "\tclf__n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('clf', RandomForestClassifier()),])\n",
    "\n",
    "parameters = {\n",
    "    'clf__n_estimators': (100,1000,5000),\n",
    "    'clf__max_depth': (None, 5,10, 15),\n",
    "    'clf__min_samples_split': (2,4,6)\n",
    "}\n",
    "random_search = RandomizedSearchCV(pipeline, parameters, n_iter=100, n_jobs=-1, verbose=1, cv=5, scoring=\"f1_weighted\", random_state=42)\n",
    "print(\"Performing random search\")\n",
    "print(\"Pipeline: \", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters: \")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"tuned in %0.4fs\" % (time()-t0))\n",
    "print('Best_score for Random Forest Classifier',random_search.best_score_)\n",
    "# print('Best_Parameters for Random Forest classifier',random_search.best_params_)\n",
    "\n",
    "best_parameters = random_search.best_estimator_.get_params()\n",
    "for parameter_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" %(parameter_name, best_parameters[parameter_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_search.cv_results_['params'])):\n",
    "#     exp = Experiment(api_key=comet_creds['api_key'], project_name=comet_creds['project_name'],workspace=comet_creds[\"workspace\"])\n",
    "    for k,v in random_search.cv_results_.items():\n",
    "        if k == \"params\":\n",
    "            exp.log_parameters(v[i])\n",
    "        else:\n",
    "            exp.log_metric(k,v[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RF_Tuned_Param(X,Y):\n",
    "#     # Using RandomSearchCV to find out the best set of parameters for RFR and use it for the regression model analysis and prediction:\n",
    "\n",
    "#     # Number of trees in random forest:\n",
    "#     n_estimators = [int(x) for x in np.linspace(start=5, stop= 50, num= 10)]\n",
    "\n",
    "#     # Number of features to consider at every split:\n",
    "#     max_features = ['auto','sqrt','log2']\n",
    "\n",
    "#     # Maximun number of levels in tree:\n",
    "#     max_depth = [int(x) for x in np.linspace(start=10, stop= 30, num= 5)]\n",
    "\n",
    "#     # Minimum number of samples required to split a node:\n",
    "#     min_samples_split = [5,10]\n",
    "\n",
    "#     # Minimum number of samples required at each leaf node\n",
    "#     min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "#     # Bootstrap method:\n",
    "#     bootstrap = [True,False]\n",
    "\n",
    "#     # Create the parameter grid\n",
    "#     param_grid_RF = {'n_estimators': n_estimators,\n",
    "#                   'max_features': max_features,\n",
    "#                   'max_depth': max_depth,\n",
    "#                   'min_samples_split': min_samples_split,\n",
    "#                   'min_samples_leaf': min_samples_leaf,\n",
    "#                   'bootstrap': bootstrap}\n",
    "#     pprint(param_grid_RF)\n",
    "\n",
    "#     # forest = RandomForestRegressor()\n",
    "#     random_search_forest = RandomizedSearchCV(RFR_Model, param_grid_RF, cv=3, n_jobs=6, verbose=1)\n",
    "#     random_search_forest.fit(X, Y)\n",
    "\n",
    "#     # The best parameters for the Random forest regressor obtained from GridSearch CV:\n",
    "#     print('Best_Parameters for Random Forest class',random_search_forest.best_params_)\n",
    "\n",
    "#     # The best score for Random forest regressor after GridSearch CV:\n",
    "#     print('Best_score for Random Forest Regressor',random_search_forest.best_score_)\n",
    "\n",
    "#     return random_search_forest, random_search_forest.best_params_, random_search_forest.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_randomforest.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # RF_Tuned_Param(X,y)\n",
    "dump(random_search.best_estimator_, save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank_marketting",
   "language": "python",
   "name": "bank_marketting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

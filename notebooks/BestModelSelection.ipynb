{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump\n",
    "from time import time\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/fazleem/bank-marketing/87f2bb66134d46c2a72dc14dacb9e7e3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<comet_ml.Experiment object at 0x7f3fe05904c0>\n"
     ]
    }
   ],
   "source": [
    "with open('../data/raw/comet_creds.json') as file:\n",
    "    comet_creds = json.load(file)\n",
    "exp = Experiment(api_key=comet_creds['api_key'], project_name=comet_creds['project_name'],workspace=comet_creds[\"workspace\"])    \n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../data/interim/train_data.npy\", allow_pickle=True)\n",
    "dev_data = np.load(\"../data/interim/dev_data.npy\", allow_pickle=True)\n",
    "test_data = np.load(\"../data/interim/test_data.npy\", allow_pickle=True)\n",
    "save_model = \"../models/model_randomforest.pkl\"\n",
    "save_sklearn = 'model_randomforest_new.pkl'\n",
    "n_experiments = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
    "       'target', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
    "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
    "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
    "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
    "       'education_primary', 'education_secondary', 'education_tertiary',\n",
    "       'education_unknown', 'credit_default_no', 'credit_default_yes',\n",
    "       'housing_no', 'housing_yes', 'personal_loan_no', 'personal_loan_yes',\n",
    "       'contact_type_cellular', 'contact_type_telephone',\n",
    "       'contact_type_unknown', 'month_apr', 'month_aug', 'month_dec',\n",
    "       'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar',\n",
    "       'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "       'previous_campaign_failure', 'previous_campaign_other',\n",
    "       'previous_campaign_success', 'previous_campaign_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 52)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36169, 51) (36169,)\n"
     ]
    }
   ],
   "source": [
    "combined_data = np.concatenate([train_data,dev_data])\n",
    "df = pd.DataFrame(combined_data, columns=columns)\n",
    "df_test = pd.DataFrame(test_data, columns=columns)\n",
    "\n",
    "y = df['target']\n",
    "X = df.drop(['target'], axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9042, 51) (9042,)\n"
     ]
    }
   ],
   "source": [
    "Y_test = df_test['target']\n",
    "X_test = df_test.drop(['target'], axis=1)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipelines for Random forest and Gradient Boost\n",
    "## Pipeline creation steps\n",
    "## 1. Data Preprocessing using Standard Scalar\n",
    "## 2. Apply classifier\n",
    "\n",
    "pipeline_rf = Pipeline([('scalar1', StandardScaler()), ('rf_classifier',RandomForestClassifier())])\n",
    "pipeline_gb = Pipeline([('scalar1', StandardScaler()), ('gb_classifier',GradientBoostingClassifier())])\n",
    "pipelines = [pipeline_rf, pipeline_gb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "best_model = 0\n",
    "best_classifier = ''\n",
    "\n",
    "pipe_dict = {0:'Random Forest', 1:'Gradient Boost'}\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.9074319840743198\n",
      "Gradient Boost Test Accuracy: 0.9106392391063924\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\" .format(pipe_dict[i], model.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy:Gradient Boost\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test,Y_test)>best_accuracy:\n",
    "        best_accuracy = model.score(X_test,Y_test)\n",
    "        best_model = model\n",
    "        best_classifier = i\n",
    "\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from estimator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from estimator\n",
      "COMET ERROR: Failed to extract parameters from estimator\n"
     ]
    }
   ],
   "source": [
    "#create a pipeline\n",
    "pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "#create dictionary with learning algorithms and their hyper parameters\n",
    "\n",
    "random_params = [\n",
    "    {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': (100,1000,5000),\n",
    "    'classifier__max_depth': (None, 5,10, 15),\n",
    "    'classifier__min_samples_split': (2,4,6)\n",
    "    },\n",
    "    {\n",
    "    'classifier': [GradientBoostingClassifier()],\n",
    "    'classifier__n_estimators': (100,1000,5000),\n",
    "    'classifier__max_depth': (None, 5,10, 15),\n",
    "    'classifier__min_samples_split': (2,4,6)\n",
    "    }\n",
    "]\n",
    "randomsearch = RandomizedSearchCV(pipe, random_params, n_iter=10, n_jobs=-1, verbose=1, cv=5, scoring=\"f1_weighted\", random_state=42)\n",
    "best_model = randomsearch.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f9c268e95ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(\"{} Train acc: {}\" .format(randomcv_dict[index], model.score(X,y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# print(\"{} Train acc: {}\" .format(randomcv_dict[index], model.score(X,y))\n",
    "print(best_model.best_estimator_)\n",
    "print(best_model.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # create a pipeline\n",
    "# pipeline_rf = Pipeline([('clfrf', RandomForestClassifier()),])\n",
    "# pipeline_gboost = Pipeline([('clfgb', GradientBoostingClassifier()),])\n",
    "# rf_parameters = {\n",
    "#     'clfrf__n_estimators': (100,1000,5000),\n",
    "#     'clfrf__max_depth': (None, 5,10, 15),\n",
    "#     'clfrf__min_samples_split': (2,4,6)\n",
    "# }\n",
    "# gb_parameters = {\n",
    "#     'clfgb__n_estimators': (100,1000,5000),\n",
    "#     'clfgb__max_depth': (None, 5,10, 15),\n",
    "#     'clfgb__min_samples_split': (2,4,6)\n",
    "#         }\n",
    "# sorted(pipeline_rf.get_params().keys())\n",
    "\n",
    "\n",
    "# random_search_rf = RandomizedSearchCV(pipeline_rf, rf_parameters, n_iter=10, n_jobs=-1, verbose=1, cv=5, scoring=\"f1_weighted\", random_state=42)\n",
    "# random_search_gb = RandomizedSearchCV(pipeline_gboost, gb_parameters, n_iter=10, scoring='f1_weighted', n_jobs=-1, cv=5, verbose=1, random_state=1001)\n",
    "# # list of searches that i want to run\n",
    "# pipelines = [random_search_rf,random_search_gb]\n",
    "\n",
    "# #create dict\n",
    "# randomcv_dict = {0:'Random Forest', 1:'Gradient Boost'}\n",
    "\n",
    "    \n",
    "# # print(\"Performing random search\")\n",
    "# # print(\"Pipeline: \", [name for name, _ in pipeline.steps])\n",
    "# # print(\"parameters: \")\n",
    "# # pprint(parameters)\n",
    "# # t0 = time()\n",
    "# # random_search.fit(X, y)\n",
    "# # print(\"tuned in %0.4fs\" % (time()-t0))\n",
    "# # print('Best_score for Random Forest Classifier',random_search.best_score_)\n",
    "# # # print('Best_Parameters for Random Forest classifier',random_search.best_params_)\n",
    "\n",
    "# # best_parameters = random_search.best_estimator_.get_params()\n",
    "# # for parameter_name in sorted(parameters.keys()):\n",
    "# #     print(\"\\t%s: %r\" %(parameter_name, best_parameters[parameter_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=5,\n",
      "                   estimator=Pipeline(steps=[('clfrf',\n",
      "                                              RandomForestClassifier())]),\n",
      "                   n_jobs=-1,\n",
      "                   param_distributions={'clfrf__max_depth': (None, 5, 10, 15),\n",
      "                                        'clfrf__min_samples_split': (2, 4, 6),\n",
      "                                        'clfrf__n_estimators': (100, 1000,\n",
      "                                                                5000)},\n",
      "                   random_state=42, scoring='f1_weighted', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "print(random_search_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from estimator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from estimator\n",
      "COMET ERROR: Failed to extract parameters from estimator\n",
      "COMET ERROR: Failed to extract parameters from estimator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazleem/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "COMET ERROR: Failed to extract parameters from estimator\n",
      "COMET ERROR: Failed to extract parameters from estimator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train acc: 0.9820184470290868\n",
      "Gradient Boost Train acc: 0.9237188683919911\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_accuracy = 0.0\n",
    "best_model = 0\n",
    "best_search = ''\n",
    "\n",
    "#fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X,y)\n",
    "\n",
    "for index,model in enumerate(pipelines):\n",
    "    print(\"{} Train acc: {}\" .format(randomcv_dict[index], model.score(X,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=5,\n",
      "                   estimator=Pipeline(steps=[('clfgb',\n",
      "                                              GradientBoostingClassifier())]),\n",
      "                   n_jobs=-1,\n",
      "                   param_distributions={'clfgb__max_depth': (None, 5, 10, 15),\n",
      "                                        'clfgb__min_samples_split': (2, 4, 6),\n",
      "                                        'clfgb__n_estimators': (100, 1000,\n",
      "                                                                5000)},\n",
      "                   random_state=1001, scoring='f1_weighted', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test acc: 0.8968997939122643\n",
      "Gradient Boost Test acc: 0.9033124885223582\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipelines:\n",
    "    pipe.predict(X_test)\n",
    "\n",
    "for index,model in enumerate(pipelines):\n",
    "    print(\"{} Test acc: {}\" .format(randomcv_dict[index], model.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pipe.cv_results_['params'])):\n",
    "#     exp = Experiment(api_key=comet_creds['api_key'], project_name=comet_creds['project_name'],workspace=comet_creds[\"workspace\"])\n",
    "    for index,values in pipe.cv_results_.items():\n",
    "        if index == \"params\":\n",
    "            exp.log_parameters(values[i])\n",
    "        else:\n",
    "            exp.log_metric(index,values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RF_Tuned_Param(X,Y):\n",
    "#     # Using RandomSearchCV to find out the best set of parameters for RFR and use it for the regression model analysis and prediction:\n",
    "\n",
    "#     # Number of trees in random forest:\n",
    "#     n_estimators = [int(x) for x in np.linspace(start=5, stop= 50, num= 10)]\n",
    "\n",
    "#     # Number of features to consider at every split:\n",
    "#     max_features = ['auto','sqrt','log2']\n",
    "\n",
    "#     # Maximun number of levels in tree:\n",
    "#     max_depth = [int(x) for x in np.linspace(start=10, stop= 30, num= 5)]\n",
    "\n",
    "#     # Minimum number of samples required to split a node:\n",
    "#     min_samples_split = [5,10]\n",
    "\n",
    "#     # Minimum number of samples required at each leaf node\n",
    "#     min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "#     # Bootstrap method:\n",
    "#     bootstrap = [True,False]\n",
    "\n",
    "#     # Create the parameter grid\n",
    "#     param_grid_RF = {'n_estimators': n_estimators,\n",
    "#                   'max_features': max_features,\n",
    "#                   'max_depth': max_depth,\n",
    "#                   'min_samples_split': min_samples_split,\n",
    "#                   'min_samples_leaf': min_samples_leaf,\n",
    "#                   'bootstrap': bootstrap}\n",
    "#     pprint(param_grid_RF)\n",
    "\n",
    "#     # forest = RandomForestRegressor()\n",
    "#     random_search_forest = RandomizedSearchCV(RFR_Model, param_grid_RF, cv=3, n_jobs=6, verbose=1)\n",
    "#     random_search_forest.fit(X, Y)\n",
    "\n",
    "#     # The best parameters for the Random forest regressor obtained from GridSearch CV:\n",
    "#     print('Best_Parameters for Random Forest class',random_search_forest.best_params_)\n",
    "\n",
    "#     # The best score for Random forest regressor after GridSearch CV:\n",
    "#     print('Best_score for Random Forest Regressor',random_search_forest.best_score_)\n",
    "\n",
    "#     return random_search_forest, random_search_forest.best_params_, random_search_forest.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RF_Tuned_Param(X,y)\n",
    "dump(pipe.best_estimator_, open(save_model,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_estimator_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7373866d34c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_estimator_' is not defined"
     ]
    }
   ],
   "source": [
    "best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a=pickle.load(open('/home/fazleem/Desktop/DataScience/bank_marketting/models/model_randomforest.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
